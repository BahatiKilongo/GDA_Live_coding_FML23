{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GDA Implementation.\n",
        "\n",
        "Implement the Gaussian Discriminant Analysis (GDA) learning algorithm following the steps as discussed in class.\n",
        "\n",
        "INSTRUCTION: Rename your notebook as: <br>\n",
        "`firstName_LastName_Live_coding_GDA.ipynb`.\n",
        "\n",
        "Notes: \n",
        "* Do not use any built-in functions to complete a task;\n",
        "* Do not import additional libraries."
      ],
      "metadata": {
        "id": "g17Z46tmw2oZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aT5nlL-QTKwv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data\n",
        "def generate_data():\n",
        "  x, y = make_classification(n_samples= 1000, n_features=3, n_redundant=0, \n",
        "                           n_informative=3, random_state=1, \n",
        "                           n_clusters_per_class=1)\n",
        "  \n",
        "  return x,y\n",
        "\n",
        "x,y= generate_data()\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-lL4Yq9Tbzn",
        "outputId": "300bde14-0e0a-4cca-8f7d-af1ede3a0eb7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 3) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(X,y, train_size= 0.8):\n",
        "    # shuffle the data to randomize the train/test split\n",
        "    \n",
        "  np.random.seed(0) # To demonstrate that if we use the same seed value twice, we will get the same random number twice\n",
        "  n = int(len(X)*train_size)\n",
        "  indices = np.arange(len(X))\n",
        "  np.random.shuffle(indices)\n",
        "  train_idx = indices[: n]\n",
        "  test_idx = indices[n:]\n",
        "  X_train, y_train = X[train_idx], y[train_idx]\n",
        "  X_test, y_test = X[test_idx], y[test_idx]\n",
        "  \n",
        "  return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "EUgiWLDhUAAK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test= split_data(x,y, train_size= 0.8) # split your data into x_train, x_test, y_train, y_test\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr2Akm_A_FcJ",
        "outputId": "f2912779-80e3-4433-9181-04b1b212a525"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 3) (800,) (200, 3) (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def covariance(x, mu):\n",
        "  \n",
        "  \n",
        "  cov = ((x-mu).T@(x-mu))/(x.shape[0]-1)\n",
        "  \n",
        "\n",
        "  # Easy way: cov= np.cov(x, rowvar=0) but do not use it. One can use it to assess his/her result.\n",
        "  return cov"
      ],
      "metadata": {
        "id": "FrJ7GfXBHNxD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covariance(X_train,np.mean(X_train,axis = 0))"
      ],
      "metadata": {
        "id": "sDB_RHAr5kp9",
        "outputId": "1dbfd570-191e-4c53-cb0e-b99c323f8dd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.81780125, 0.00278495, 1.00021288],\n",
              "       [0.00278495, 0.98802231, 0.04507526],\n",
              "       [1.00021288, 0.04507526, 1.73006042]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cov = np.zeros((X_train.shape[1],X_train.shape[1]))\n",
        "for i in range(X_train.shape[1]):\n",
        "  mu_i = np.mean(X_train.T[i])\n",
        "  for j in range(X_train.shape[1]):\n",
        "    mu_j = np.mean(X_train.T[j])\n",
        "    cov[i,j] = (np.sum(i-mu_i*j-mu_j))/(X_train.shape[0]-1)\n",
        "\n",
        "print(cov)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6FOO_D4kyHFH",
        "outputId": "4ce839a0-a580-4c53-b284-32012c1c5d05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-4.94098787e-05 -1.31261365e-03 -1.73998842e-04]\n",
            " [ 1.20215458e-03 -1.27484309e-03 -1.35002218e-03]\n",
            " [ 2.45371903e-03  1.16474605e-03  2.27759166e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(X_train,axis = 0)"
      ],
      "metadata": {
        "id": "EIJlatAF2J-W",
        "outputId": "5a387986-f0e6-451e-8894-1d1b6da28c13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.03947849, 1.00929982, 0.06006809])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cov= np.cov(X_train,rowvar=0)\n",
        "cov"
      ],
      "metadata": {
        "id": "RyxL5Ze3xS1t",
        "outputId": "01c8a816-43cd-44bc-effe-a13803d2f575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.81780125, 0.00278495, 1.00021288],\n",
              "       [0.00278495, 0.98802231, 0.04507526],\n",
              "       [1.00021288, 0.04507526, 1.73006042]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GDA:\n",
        "  def __init__(self):\n",
        "    ## set mu, phi and sigma to None\n",
        "    self.mu = None\n",
        "    self.phi = None\n",
        "    self.sigma =None\n",
        "    \n",
        "  def fit(self,x,y):\n",
        "    k= len(np.unique(y))# Number of class.\n",
        "    d = x.shape[1]  # input dim\n",
        "    m=  x.shape[0]# Number of examples.\n",
        "    \n",
        "    ## Initialize mu, phi and sigma\n",
        "    self.mu= np.zeros((k,d))#: kxd, i.e., each row contains an individual class mu.\n",
        "    self.sigma= np.zeros((k,d,d))#: kxdxd, i.e., each row contains an individual class sigma.\n",
        "    self.phi= np.zeros(k)# d-dimension\n",
        "\n",
        "    ## START THE LEARNING: estimate mu, phi and sigma.\n",
        "    for i in range(k):\n",
        "      self.phi[i] = len(y[y==i])/x.shape[0]\n",
        "      self.mu[i] = np.mean(x[y==i],axis = 0)\n",
        "      self.sigma[i] = covariance(x[y==i],self.mu[i])\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def predict_proba(self,x):\n",
        "    # reshape or flatt x.\n",
        "    #x= x\n",
        "    d= x.shape[1]\n",
        "    k= self.mu.shape[0]\n",
        "    k_class = np.zeros((x.shape[0],k))\n",
        "    constant = (2*np.pi)**(d/2)\n",
        "    for i in range(k):\n",
        "      for j in range(x.shape[0]):\n",
        "        k_class[j,i]= np.exp(-0.5*((x[j]-self.mu[i]).T@np.linalg.inv(self.sigma[i])@(x[j]-self.mu[i]).T))/(constant*(np.linalg.det(self.sigma[i])**0.5))\n",
        "        #np.exp(-0.5*((x[j]-self.mu[i]).T@np.linalg.inv(self.sigma)@(x[j]-self.mu[i]).T))/(constant*(np.linalg.det(self.sigma[i])**0.5)) # Number of classes we have in our case it's k = 2\n",
        "    return k_class\n",
        "    ## START THE LEARNING: estimate mu, phi and sigma.\n",
        "\n",
        "  def predict(self,x):\n",
        "    predict = self.predict_proba(x) * self.phi[i]\n",
        "    y = np.argmax(predict, axis =1)\n",
        "\n",
        "    #y = np.where(predict[:,0]>predict[:,1],0,1)\n",
        "    return y\n",
        "\n",
        "    \n",
        "  \n",
        "  def accuracy(self, y, ypreds):\n",
        "    acc = np.mean(y == ypreds)\n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "id": "1ocKLDAfceF0"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= GDA()\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "l_qO0Yp1c3Is"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yproba= model.predict_proba(X_test)\n",
        "yproba"
      ],
      "metadata": {
        "id": "NKY1eojY1l4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypreds= model.predict(X_test)\n",
        "ypreds\n"
      ],
      "metadata": {
        "id": "D4clV6PK1UJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76fcec01-f631-40f6-cfa5-0fc1f255db07"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.accuracy(y_test, ypreds)"
      ],
      "metadata": {
        "id": "QgG1xPUg1ULw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e379eb8-6c16-4ce9-e22f-125fbdf738b9"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.98"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "  '''\n",
        "  The goal of this class is to create a LogisticRegression class, \n",
        "  that we will use as our model to classify data point into a corresponding class\n",
        "  '''\n",
        "  def __init__(self,lr,n_epochs):\n",
        "    self.lr = lr\n",
        "    self.n_epochs = n_epochs\n",
        "    self.train_losses = []\n",
        "    self.w = None\n",
        "    self.weight = []\n",
        "\n",
        "  def add_ones(self, x):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    one = np.ones((len(x),1))\n",
        "    x = np.hstack((one,x))\n",
        "    return x\n",
        "    #### END CODE ####\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    ##### WRITE YOUR CODE HERE ####\n",
        "    sig = 1/(1+np.exp(-x@self.w))\n",
        "    return sig\n",
        "    #### END CODE ####\n",
        "\n",
        "  def cross_entropy(self, x, y_true):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    y_pred = self.sigmoid(x)\n",
        "    loss = -(np.mean((y_true@np.log(y_pred))+(1-y_true)@np.log(1-y_pred)))\n",
        "    return loss\n",
        "    #### END CODE ####\n",
        "  \n",
        "  def predict_proba(self,x):  #This function will use the sigmoid function to compute the probalities\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    x= self.add_ones(x)\n",
        "    proba = self.sigmoid(x)\n",
        "    return proba\n",
        "    #### END CODE ####\n",
        "\n",
        "  def predict(self,x):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    probas = self.predict_proba(x)\n",
        "    output = np.where(probas>=0.5,1,0)      #convert the probalities into 0 and 1 by using a treshold=0.5\n",
        "    return output\n",
        "    #### END CODE ####\n",
        "\n",
        "  def fit(self,x,y):\n",
        "    # Add ones to x\n",
        "    x = self.add_ones(x)\n",
        "    # reshape y if needed\n",
        "    #y = y_train.reshape(len(y_train),-1)\n",
        "    # Initialize w to zeros vector >>> (x.shape[1])\n",
        "    self.w = np.zeros((x.shape[1]))\n",
        "    for epoch in range(self.n_epochs):\n",
        "      # make predictions\n",
        "      ypred = self.sigmoid(x)\n",
        "\n",
        "      #compute the gradient\n",
        "      dl = (-x.T@(y-ypred))\n",
        "\n",
        "      #update rule\n",
        "      self.w =self.w - self.lr*dl\n",
        "      #Compute and append the training loss in a list\n",
        "      loss = self.cross_entropy(x,y)\n",
        "\n",
        "      self.weight.append(self.w)\n",
        "      self.train_losses.append(loss)\n",
        "\n",
        "      if epoch%100 == 0:\n",
        "        print(f'loss for epoch {epoch}  : {loss}')\n",
        "\n",
        "  def accuracy(self,y_true, y_pred):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    acc = np.mean(y_true == y_pred)\n",
        "    return acc\n",
        "    #### END CODE ####"
      ],
      "metadata": {
        "id": "i5E0g7TDpIck"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(0.01,n_epochs=10000)\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "VFZz_Y8myVJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_train = model.predict(X_train)\n",
        "acc = model.accuracy(y_train,ypred_train)\n",
        "print(f\"The training accuracy is: {acc}\")\n",
        "print(\" \")\n",
        "\n",
        "ypred_test = model.predict(X_test)\n",
        "acc = model.accuracy(y_test,ypred_test)\n",
        "print(f\"The test accuracy is: {acc}\")"
      ],
      "metadata": {
        "id": "mAx8g6ZkyZLc",
        "outputId": "d04829c8-18ea-435f-a596-bac2454798aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is: 0.96\n",
            " \n",
            "The test accuracy is: 0.95\n"
          ]
        }
      ]
    }
  ]
}