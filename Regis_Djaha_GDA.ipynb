{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g17Z46tmw2oZ"
   },
   "source": [
    "# GDA Implementation.\n",
    "\n",
    "Implement the Gaussian Discriminant Analysis (GDA) learning algorithm following the steps as discussed in class.\n",
    "\n",
    "INSTRUCTION: Rename your notebook as: <br>\n",
    "`firstName_LastName_Live_coding_GDA.ipynb`.\n",
    "\n",
    "Notes: \n",
    "* Do not use any built-in functions to complete a task;\n",
    "* Do not import additional libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "aT5nlL-QTKwv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-lL4Yq9Tbzn",
    "outputId": "30937363-7f7e-4360-e123-b4cdb1ebe441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# Generate data\n",
    "def generate_data():\n",
    "  x, y = make_classification(n_samples= 1000, n_features=3, n_redundant=0, \n",
    "                           n_informative=3, random_state=1, \n",
    "                           n_clusters_per_class=1)\n",
    "  \n",
    "  return x,y\n",
    "\n",
    "x,y= generate_data() # get data\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EUgiWLDhUAAK"
   },
   "outputs": [],
   "source": [
    "def split_data(x,y, train_size= 0.8):\n",
    "    # shuffle the data to randomize the train/test split\n",
    "    indices = np.random.permutation(len(y))\n",
    "    \n",
    "    # Split the shuffled indices into training and testing sets\n",
    "    train_indices = indices[:int(train_size*len(y))]\n",
    "    test_indices = indices[int(train_size*len(y)):]\n",
    "    \n",
    "    # Use the shuffled indices to extract the corresponding data\n",
    "    x_train, x_test = x[train_indices], x[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 3) (800,) (200, 3) (200,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test= split_data(x, y, train_size=0.8)# split your data into x_train, x_test, y_train, y_test\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def covariance(x, mu):\n",
    "    d = x.shape[1]\n",
    "    mu=np.mean(x,axis=0)\n",
    "    cov = np.zeros((d, d))\n",
    "    for i in range(d):\n",
    "        for j in range(d):\n",
    "            cov[i, j] = np.sum((x[:,i] - mu[i]) * (x[:,j] - mu[j])) / (len(x) - 1)\n",
    "    return cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01298493  0.99925415  0.02975341]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(x,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.84495325, 0.02790646, 1.00137533],\n",
       "       [0.02790646, 1.00170721, 0.05539176],\n",
       "       [1.00137533, 0.05539176, 1.74832   ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu=np.mean(x,axis=0)\n",
    "covariance(x, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.84495325, 0.02790646, 1.00137533],\n",
       "       [0.02790646, 1.00170721, 0.05539176],\n",
       "       [1.00137533, 0.05539176, 1.74832   ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(x,rowvar=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAUSSIAN DISCRIMINANT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "1ocKLDAfceF0"
   },
   "outputs": [],
   "source": [
    "class GDA:\n",
    "  def __init__(self):\n",
    "    ## set mu, phi and sigma to None\n",
    "    self.mu=None\n",
    "    self.phi=None\n",
    "    self.sigma=None\n",
    "    \n",
    "  def fit(self,x,y):\n",
    "    k=2 #np.unique(y).size  # Number of class.\n",
    "    d=x.shape[1] # input dim\n",
    "    m= x.shape[0]# Number of examples.\n",
    "    \n",
    "    ## Initialize mu, phi and sigma\n",
    "    self.mu= np.zeros((k,d))#: kxd, i.e., each row contains an individual class mu.\n",
    "    self.sigma= np.zeros((k,d,d))#: kxdxd, i.e., each row contains an individual class sigma.\n",
    "    self.phi= np.zeros((k))# d-dimension\n",
    "\n",
    "    ## START THE LEARNING: estimate mu, phi and sigma.\n",
    "    for lab in range(k):\n",
    "        \n",
    "        self.phi[lab] = np.sum(lab==y)/m \n",
    "        self.mu[lab] = np.mean(x[lab==y], axis=0)\n",
    "        self.sigma[lab] = covariance(x[lab==y], self.mu[lab])\n",
    "    return self.phi,self.mu, self.sigma\n",
    "            \n",
    "            \n",
    "\n",
    "  def predict_proba(self,x):\n",
    "    # reshape or flatt x.\n",
    "    #x= x.reshape(-1, self.mu.shape[1])\n",
    "    #x=x.reshape(-1,1)\n",
    "    #x=self.mu.shape[0]\n",
    "    d= x.shape[0]\n",
    "    #k_class = self.mu.shape[0] \n",
    "    k_class= self.mu.shape[0]  # Number of classes we have in our case it's k = 2\n",
    "    probabilities = np.zeros((d, k_class))\n",
    "    det_cov = []\n",
    "    inv_cov = []\n",
    "    \n",
    "    ## START THE LEARNING: estimate mu, phi and sigma.\n",
    "    for lab in range(k_class):\n",
    "        det_cov= np.linalg.det(self.sigma[lab])\n",
    "        inv_cov=np.linalg.inv(self.sigma[lab])\n",
    "        for j in range(x.shape[0]):\n",
    "            first_term=1/((2*np.pi)**(d/2)*(det_cov**0.5))\n",
    "            #first_term=((1/(((2*np.pi)**(d/2))*(det_cov**0.5)))\n",
    "            exponential=-0.5*((x[j]-self.mu[lab]).T)@(inv_cov)@(x[j]-self.mu[lab])\n",
    "            second_term=np.exp(exponential)\n",
    "            probabilities[j, lab] = first_term*second_term*self.phi[lab]\n",
    "    return probabilities\n",
    "\n",
    "  def predict(self,x):\n",
    "    predict=self.predict_proba(x)\n",
    "    \n",
    "    y = np.argmax(predict,axis = 1)\n",
    "    #Predict = np.argmax(self.predict_proba(x))\n",
    "    return y\n",
    "    \n",
    "  \n",
    "  def accuracy(self, y, ypreds):\n",
    "#     ypred = self.predict(y)\n",
    "    result = np.mean(y == ypreds)\n",
    "    return result * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "l_qO0Yp1c3Is"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.4975, 0.5025]),\n",
       " array([[ 1.00809629,  1.04276141,  1.00735477],\n",
       "        [-1.00501945,  0.95252045, -0.92191288]]),\n",
       " array([[[ 0.87109161, -0.38774776, -0.05940387],\n",
       "         [-0.38774776,  1.58972621,  0.09334442],\n",
       "         [-0.05940387,  0.09334442,  0.03860804]],\n",
       " \n",
       "        [[ 0.82005339,  0.3439849 ,  0.13349403],\n",
       "         [ 0.3439849 ,  0.35327877, -0.07034022],\n",
       "         [ 0.13349403, -0.07034022,  1.54533643]]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= GDA()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NKY1eojY1l4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.26187381e-116, 1.15377018e-080],\n",
       "       [1.80730222e-080, 9.38257218e-088],\n",
       "       [6.63937481e-130, 1.24645211e-080],\n",
       "       [6.48388115e-161, 4.66049116e-081],\n",
       "       [2.32062356e-080, 3.26112407e-085],\n",
       "       [1.51219577e-127, 9.60901530e-083],\n",
       "       [1.45823988e-080, 1.01766456e-082],\n",
       "       [9.93850009e-192, 1.52830103e-081],\n",
       "       [9.24763426e-081, 2.02662746e-082],\n",
       "       [7.54950605e-091, 8.75778737e-081],\n",
       "       [6.61513568e-131, 5.31894264e-081],\n",
       "       [5.17752242e-081, 2.99149739e-081],\n",
       "       [3.09689945e-081, 4.44128222e-084],\n",
       "       [3.43770667e-081, 9.86244697e-083],\n",
       "       [9.90870909e-081, 3.18824264e-083],\n",
       "       [3.56013934e-080, 5.72779111e-082],\n",
       "       [9.58955578e-082, 3.93930844e-090],\n",
       "       [3.64994082e-095, 1.32358594e-081],\n",
       "       [3.26413987e-082, 5.90951279e-097],\n",
       "       [2.75301397e-116, 3.19759618e-081],\n",
       "       [2.91089092e-081, 1.97368464e-087],\n",
       "       [5.49020982e-170, 8.42142546e-082],\n",
       "       [5.06856966e-094, 5.28055399e-081],\n",
       "       [1.38619299e-080, 2.20993198e-083],\n",
       "       [6.71507627e-083, 1.67052835e-081],\n",
       "       [2.07561168e-080, 4.13398476e-082],\n",
       "       [1.89076074e-081, 5.11817243e-095],\n",
       "       [1.87140309e-080, 8.54165003e-083],\n",
       "       [8.09740504e-081, 1.22656145e-082],\n",
       "       [4.03688461e-081, 3.74232755e-084],\n",
       "       [1.95067591e-093, 1.14981055e-080],\n",
       "       [2.67415750e-080, 7.57240594e-085],\n",
       "       [2.33637426e-080, 9.46531566e-083],\n",
       "       [1.12423327e-228, 1.53712549e-081],\n",
       "       [2.59229722e-129, 1.35019891e-080],\n",
       "       [1.47928132e-117, 4.49710013e-081],\n",
       "       [7.15529026e-111, 8.93916982e-081],\n",
       "       [5.77090714e-082, 2.24798917e-081],\n",
       "       [2.37706023e-102, 2.98320296e-081],\n",
       "       [1.19818846e-131, 1.03544084e-080],\n",
       "       [1.00563708e-084, 1.86113977e-081],\n",
       "       [2.07151907e-081, 2.83166311e-083],\n",
       "       [1.42812063e-080, 6.44453944e-089],\n",
       "       [5.79312493e-087, 8.53509368e-081],\n",
       "       [5.90362433e-085, 4.32830568e-081],\n",
       "       [9.65211411e-081, 2.25700718e-083],\n",
       "       [1.71180625e-091, 8.89193469e-081],\n",
       "       [5.63503829e-081, 8.36193940e-084],\n",
       "       [1.06637186e-080, 5.40872755e-086],\n",
       "       [1.06363063e-092, 9.18434883e-081],\n",
       "       [2.77127435e-087, 1.78670738e-082],\n",
       "       [7.72601765e-105, 1.17910216e-080],\n",
       "       [2.86036450e-223, 7.01918785e-082],\n",
       "       [1.80552716e-080, 8.59086391e-083],\n",
       "       [1.54633623e-113, 7.98923641e-081],\n",
       "       [3.58211446e-080, 2.51781319e-082],\n",
       "       [1.75180226e-090, 1.05655824e-080],\n",
       "       [4.61886593e-099, 2.55828791e-081],\n",
       "       [3.88372377e-153, 3.19761834e-081],\n",
       "       [1.77296832e-080, 2.08712653e-081],\n",
       "       [3.27614234e-085, 4.99110529e-081],\n",
       "       [3.34506609e-168, 3.16227880e-081],\n",
       "       [7.63751348e-081, 2.20018763e-081],\n",
       "       [2.55420921e-099, 9.83571197e-081],\n",
       "       [1.00750524e-080, 1.00284830e-083],\n",
       "       [2.10369911e-093, 8.29734534e-081],\n",
       "       [3.34819857e-080, 2.62476468e-082],\n",
       "       [2.94977372e-080, 1.65462613e-084],\n",
       "       [4.18568707e-098, 7.66215116e-081],\n",
       "       [3.66440104e-116, 4.11082401e-081],\n",
       "       [1.53086210e-093, 4.53764776e-081],\n",
       "       [1.45828145e-097, 9.97453517e-081],\n",
       "       [5.41079751e-081, 6.42308414e-092],\n",
       "       [2.04274844e-111, 5.78756078e-081],\n",
       "       [3.11928676e-086, 9.23473621e-081],\n",
       "       [2.80054970e-124, 2.63645539e-081],\n",
       "       [4.86293388e-081, 6.21846289e-086],\n",
       "       [1.64044349e-080, 5.56633266e-082],\n",
       "       [7.59559664e-091, 9.84342714e-081],\n",
       "       [8.57540904e-081, 1.45969106e-081],\n",
       "       [1.31584743e-178, 2.35299031e-081],\n",
       "       [1.19986487e-081, 4.86244440e-092],\n",
       "       [8.20565869e-087, 6.61521730e-082],\n",
       "       [2.84258509e-081, 2.11980988e-084],\n",
       "       [6.24556485e-081, 3.74371360e-088],\n",
       "       [1.93899661e-080, 2.42639485e-082],\n",
       "       [2.39671258e-119, 1.35435853e-080],\n",
       "       [7.22387272e-086, 8.16852961e-081],\n",
       "       [2.42474991e-086, 4.94871332e-081],\n",
       "       [2.17622594e-080, 4.65500547e-082],\n",
       "       [3.12124998e-080, 4.52586908e-083],\n",
       "       [1.10966335e-080, 2.46554205e-087],\n",
       "       [7.00309167e-081, 2.21456614e-081],\n",
       "       [5.61395019e-104, 9.46605772e-081],\n",
       "       [7.95328683e-081, 1.44599290e-083],\n",
       "       [1.27809008e-082, 3.94936827e-081],\n",
       "       [2.41869753e-080, 1.93282811e-082],\n",
       "       [1.48897347e-102, 7.09502837e-081],\n",
       "       [1.03247131e-080, 1.08024644e-083],\n",
       "       [4.30433003e-151, 7.05184660e-081],\n",
       "       [4.52293201e-147, 8.41874412e-081],\n",
       "       [1.77942340e-087, 1.53558752e-081],\n",
       "       [5.86344409e-081, 2.57928705e-095],\n",
       "       [1.05532569e-080, 9.34296156e-091],\n",
       "       [5.54856344e-192, 3.92039738e-081],\n",
       "       [1.22746841e-080, 8.92994913e-083],\n",
       "       [6.75766523e-088, 3.66654267e-081],\n",
       "       [3.55783503e-081, 2.11875293e-083],\n",
       "       [8.77819751e-133, 1.30588311e-080],\n",
       "       [1.78811292e-080, 1.49058490e-087],\n",
       "       [2.67287952e-115, 1.06614802e-080],\n",
       "       [1.44985460e-080, 1.44735623e-082],\n",
       "       [1.40921191e-080, 3.80356995e-085],\n",
       "       [1.10207632e-084, 6.29244369e-082],\n",
       "       [5.36695818e-107, 9.44510724e-081],\n",
       "       [5.32139616e-081, 1.85688968e-084],\n",
       "       [8.94664184e-081, 8.96893431e-084],\n",
       "       [2.01113309e-080, 2.36476442e-082],\n",
       "       [7.41660314e-081, 1.21441152e-089],\n",
       "       [1.64425186e-080, 1.80545838e-086],\n",
       "       [1.91345992e-080, 5.55355585e-082],\n",
       "       [1.22547391e-225, 1.48026207e-081],\n",
       "       [2.15621820e-101, 9.27372779e-081],\n",
       "       [1.78685162e-080, 4.72584080e-084],\n",
       "       [1.62979994e-080, 2.41203319e-082],\n",
       "       [1.30553150e-080, 3.87350150e-082],\n",
       "       [1.35078608e-081, 9.55640608e-086],\n",
       "       [1.67335295e-201, 6.45233629e-082],\n",
       "       [5.69499966e-123, 5.42784826e-081],\n",
       "       [1.16250936e-083, 1.36286598e-081],\n",
       "       [1.31070675e-080, 7.69609983e-082],\n",
       "       [4.59368299e-082, 3.03101313e-093],\n",
       "       [6.10300048e-081, 1.63273431e-084],\n",
       "       [3.01778068e-207, 2.26413887e-081],\n",
       "       [5.98455913e-102, 5.69856811e-081],\n",
       "       [1.78062897e-081, 2.59001183e-084],\n",
       "       [3.45385224e-105, 9.83125903e-081],\n",
       "       [2.60108293e-082, 1.29411940e-094],\n",
       "       [2.68980247e-148, 2.16466382e-081],\n",
       "       [5.42865016e-084, 1.03085552e-081],\n",
       "       [1.58498793e-080, 5.11828945e-082],\n",
       "       [9.84925468e-082, 6.51726634e-083],\n",
       "       [2.87029998e-090, 1.17526274e-080],\n",
       "       [3.00103580e-098, 9.78224616e-081],\n",
       "       [1.51229747e-080, 1.75366788e-082],\n",
       "       [5.64765719e-084, 2.63185344e-082],\n",
       "       [3.78053879e-082, 1.20664907e-111],\n",
       "       [1.43946175e-080, 5.09575867e-090],\n",
       "       [4.16027162e-098, 1.31713900e-080],\n",
       "       [4.17327918e-311, 6.85696162e-083],\n",
       "       [3.00246230e-080, 1.66585990e-084],\n",
       "       [3.05963873e-178, 4.01362817e-081],\n",
       "       [2.50502415e-082, 2.09901394e-082],\n",
       "       [2.72310577e-080, 1.28560052e-082],\n",
       "       [1.01208437e-080, 1.32837758e-091],\n",
       "       [9.51835199e-087, 7.01340587e-081],\n",
       "       [6.70237756e-182, 5.25503369e-081],\n",
       "       [3.05948544e-080, 8.87004105e-082],\n",
       "       [5.30890958e-081, 9.47937670e-082],\n",
       "       [1.92193369e-080, 1.19364606e-084],\n",
       "       [1.42735382e-080, 1.13719556e-086],\n",
       "       [3.32715813e-222, 1.42410566e-081],\n",
       "       [9.67408522e-081, 3.67626205e-082],\n",
       "       [6.06249669e-104, 1.24226428e-080],\n",
       "       [2.96034649e-080, 1.11556961e-081],\n",
       "       [9.94996924e-081, 4.38751041e-083],\n",
       "       [7.72163475e-081, 2.34670113e-083],\n",
       "       [8.10465306e-091, 9.33054551e-082],\n",
       "       [2.85712105e-081, 1.27377539e-083],\n",
       "       [8.63844068e-082, 2.18242649e-089],\n",
       "       [1.57179162e-258, 9.60546663e-083],\n",
       "       [8.74552907e-093, 8.58411761e-081],\n",
       "       [2.20736079e-080, 4.21714324e-083],\n",
       "       [2.32192639e-145, 3.10647611e-081],\n",
       "       [2.55921035e-081, 4.12609285e-090],\n",
       "       [1.55780306e-080, 9.90657062e-083],\n",
       "       [2.26559090e-080, 7.94732598e-083],\n",
       "       [1.95467746e-103, 1.13660511e-080],\n",
       "       [4.39324846e-083, 4.53345038e-081],\n",
       "       [2.19622815e-166, 1.21341983e-081],\n",
       "       [6.52435961e-100, 1.28256192e-080],\n",
       "       [3.46810452e-080, 1.62177205e-082],\n",
       "       [6.37336465e-081, 3.18194729e-084],\n",
       "       [1.80798359e-118, 1.04946149e-080],\n",
       "       [2.12273497e-089, 5.23553161e-081],\n",
       "       [2.76071578e-080, 1.79131254e-082],\n",
       "       [4.01218063e-132, 4.96728311e-082],\n",
       "       [3.57065601e-137, 1.06177002e-080],\n",
       "       [6.41411529e-127, 4.99894659e-081],\n",
       "       [5.39519065e-294, 1.78797326e-082],\n",
       "       [1.68126344e-099, 8.03560259e-081],\n",
       "       [9.14110480e-081, 3.41281438e-084],\n",
       "       [3.26010654e-092, 8.65584660e-081],\n",
       "       [3.26435545e-081, 5.57805588e-082],\n",
       "       [3.64240665e-115, 3.65527585e-081],\n",
       "       [8.80981767e-081, 2.61582960e-083],\n",
       "       [7.93372114e-081, 1.33664426e-085],\n",
       "       [6.44658582e-168, 6.87064691e-082],\n",
       "       [1.13185454e-080, 1.39991289e-090],\n",
       "       [1.81367293e-080, 1.46543064e-087]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yproba= model.predict_proba(X_test)\n",
    "yproba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "D4clV6PK1UJK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypreds= model.predict(X_test)\n",
    "ypreds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "QgG1xPUg1ULw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.accuracy(y_test, ypreds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OpXYY-yj1UOj"
   },
   "source": [
    "## LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "  '''\n",
    "  The goal of this class is to create a LogisticRegression class, \n",
    "  that we will use as our model to classify data point into a corresponding class\n",
    "  '''\n",
    "  def __init__(self,lr,n_epochs):\n",
    "    self.lr = lr\n",
    "    self.n_epochs = n_epochs\n",
    "    self.train_losses = []\n",
    "    self.w = None\n",
    "    self.weight = []\n",
    "\n",
    "  def add_ones(self, x):\n",
    "    ##### WRITE YOUR CODE HERE #####\n",
    "    one = np.ones((x.shape[0],1))\n",
    "    return np.hstack((one,x))\n",
    "    #### END CODE ####\n",
    "\n",
    "  def sigmoid(self, x):\n",
    "    return 1/(1+np.exp(-x@self.w))\n",
    "\n",
    "\n",
    "  def cross_entropy(self, x, y_true):\n",
    "    ##### WRITE YOUR CODE HERE #####\n",
    "    y_pred = self.sigmoid(x)\n",
    "    loss = -np.mean(y_true*np.log(y_pred)+(1-y_true)*np.log(1-y_pred))\n",
    "    return loss\n",
    "    #### END CODE ####\n",
    "  \n",
    "  def predict_proba(self,x):  #This function will use the sigmoid function to compute the probalities\n",
    "    ##### WRITE YOUR CODE HERE #####\n",
    "    x= self.add_ones(x)\n",
    "    proba = self.sigmoid(x)\n",
    "    return proba\n",
    "    #### END CODE ####\n",
    "\n",
    "  def predict(self,x):\n",
    "    ##### WRITE YOUR CODE HERE #####\n",
    "    probas = self.predict_proba(x)\n",
    "    output = [0 if p<0.5 else 1 for p in probas]#np.where(probas>=0.5, 1, 0)      #convert the probalities into 0 and 1 by using a treshold=0.5\n",
    "    return output\n",
    "    #### END CODE ####\n",
    "\n",
    "  def fit(self,x,y):\n",
    "    # Add ones to x\n",
    "    x=self.add_ones(x)\n",
    "\n",
    "    # reshape y if needed\n",
    "    y=y.reshape(-1,1)\n",
    "\n",
    "    # Initialize w to zeros vector >>> (x.shape[1])\n",
    "    self.w=np.zeros((x.shape[1],1))\n",
    "\n",
    "    for epoch in range(self.n_epochs):\n",
    "      # make predictions\n",
    "      ypred = self.sigmoid(x)\n",
    "\n",
    "      #compute the gradient\n",
    "      dl = (-1/x.shape[0])*(x.T@(y-ypred))\n",
    "\n",
    "      #update rule\n",
    "      self.w=self.w-self.lr*dl\n",
    "\n",
    "      #Compute and append the training loss in a list\n",
    "      loss = self.cross_entropy(x,y)\n",
    "      self.train_losses.append(loss)\n",
    "\n",
    "      if epoch%1000 == 0:\n",
    "        print(f'loss for epoch {epoch}  : {loss}')\n",
    "\n",
    "  def accuracy(self,y_true, y_pred):\n",
    "    ##### WRITE YOUR CODE HERE #####\n",
    "    acc = np.mean(y_true==y_pred)*100\n",
    "    return acc\n",
    "    #### END CODE ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for epoch 0  : 0.688302013550846\n",
      "loss for epoch 1000  : 0.20128292123511357\n",
      "loss for epoch 2000  : 0.17848901478927728\n",
      "loss for epoch 3000  : 0.16995555445599156\n",
      "loss for epoch 4000  : 0.16527281890677117\n",
      "loss for epoch 5000  : 0.16221508279645674\n",
      "loss for epoch 6000  : 0.16002072337962914\n",
      "loss for epoch 7000  : 0.15835566428544698\n",
      "loss for epoch 8000  : 0.1570472013583435\n",
      "loss for epoch 9000  : 0.1559947176174476\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(0.01,n_epochs=10000)\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 95.375\n",
      " \n",
      "The test accuracy is: 95.5\n"
     ]
    }
   ],
   "source": [
    "ypred_train = model.predict(X_train)\n",
    "acc = model.accuracy(y_train,ypred_train)\n",
    "print(f\"The training accuracy is: {acc}\")\n",
    "print(\" \")\n",
    "\n",
    "ypred_test = model.predict(X_test)\n",
    "acc = model.accuracy(y_test,ypred_test)\n",
    "print(f\"The test accuracy is: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
