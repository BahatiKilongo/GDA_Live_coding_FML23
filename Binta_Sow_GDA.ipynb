{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BintaSOW1/GDA_Live_coding_FML23/blob/main/Binta_Sow_GDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GDA Implementation.\n",
        "\n",
        "Implement the Gaussian Discriminant Analysis (GDA) learning algorithm following the steps as discussed in class.\n",
        "\n",
        "INSTRUCTION: Rename your notebook as: <br>\n",
        "`firstName_LastName_Live_coding_GDA.ipynb`.\n",
        "\n",
        "Notes: \n",
        "* Do not use any built-in functions to complete a task;\n",
        "* Do not import additional libraries."
      ],
      "metadata": {
        "id": "g17Z46tmw2oZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "aT5nlL-QTKwv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data\n",
        "def generate_data():\n",
        "  x, y = make_classification(n_samples= 1000, n_features=3, n_redundant=0, \n",
        "                           n_informative=3, random_state=1, \n",
        "                           n_clusters_per_class=1)\n",
        "  \n",
        "  return x,y\n",
        "\n"
      ],
      "metadata": {
        "id": "_-lL4Yq9Tbzn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y= generate_data()\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXcZynBvg80M",
        "outputId": "97d24cdb-61c9-432e-c455-efb8047fe8a9"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 3) (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(x,y, train_size= 0.8):\n",
        "    # shuffle the data to randomize the train/test split\n",
        "  \n",
        "\n",
        "  np.random.seed(0) \n",
        "  \n",
        "  train_size = 0.8\n",
        "  n = int(len(x)*train_size)\n",
        "  indices = np.arange(len(x))\n",
        "  np.random.shuffle(indices)\n",
        "  train_idx = indices[: n]\n",
        "  test_idx = indices[n:]\n",
        "  X_train, y_train = x[train_idx], y[train_idx]\n",
        "  X_test, y_test = x[test_idx], y[test_idx]\n",
        "\n",
        "  return X_train, y_train, X_test, y_test\n",
        "  "
      ],
      "metadata": {
        "id": "EUgiWLDhUAAK"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_test, y_test= split_data(x,y, train_size= 0.8) # split your data into x_train, x_test, y_train, y_test\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cr2Akm_A_FcJ",
        "outputId": "c496a551-c8e0-4630-b114-f04ec09e5397"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(800, 3) (800,) (200, 3) (200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def covariance(x, mu):\n",
        "  N,d = x.shape\n",
        "  K= mu.shape[0]\n",
        "  sigma = np.zeros((d,d))\n",
        "  for k in range(K):\n",
        "   for i in range(d):\n",
        "     for j in range(d):\n",
        "       sigma[i,j] = (1/(N-1))* np.sum((x[:,i] - mu[i]) * (x[:,j] - mu[j]))\n",
        "       \n",
        "  return sigma\n"
      ],
      "metadata": {
        "id": "MhJ_czWc4RuL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covariance(x,x.mean(axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nw9Ibdh824SO",
        "outputId": "3507785d-80d6-451c-93c8-d1ae5284027e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.84495325, 0.02790646, 1.00137533],\n",
              "       [0.02790646, 1.00170721, 0.05539176],\n",
              "       [1.00137533, 0.05539176, 1.74832   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.cov(x, rowvar=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9nxiDuT1hI-",
        "outputId": "f1d1f21b-5078-4596-b01a-0ff0ffaee81a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.84495325, 0.02790646, 1.00137533],\n",
              "       [0.02790646, 1.00170721, 0.05539176],\n",
              "       [1.00137533, 0.05539176, 1.74832   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SCrurmGhRZq3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from math import pi\n",
        "class GDA:\n",
        "  def __init__(self):\n",
        "    self.mu=None\n",
        "    self.phi = None\n",
        "    self.sigma = None\n",
        "\n",
        "  def fit(self,x,y):\n",
        "    k=np.unique(y).shape[0] # Number of class.\n",
        "    d= x.shape[1]# input dim\n",
        "    m= x.shape[0] # Number of examples.\n",
        "    \n",
        "    ## Initialize mu, phi and sigma\n",
        "    self.mu = np.zeros((k,d))#: kxd, i.e., each row contains an individual class mu.\n",
        "    self.sigma= np.zeros((k,d,d))#: kxdxd, i.e., each row contains an individual class sigma.\n",
        "    self.phi= np.zeros(d)# d-dimension\n",
        "\n",
        "    ## START THE LEARNING: estimate mu, phi and sigma.\n",
        "    for label in range(k):\n",
        "      \n",
        "      self.phi[label] = np.sum(label==y) / m\n",
        "      self.mu[label] =  np.mean(x[label==y], axis=0)\n",
        "      self.sigma[label] = covariance(x[label== y], self.mu[label])\n",
        "    # return self.mu ,self.phi ,self.sigma\n",
        "\n",
        "  def predict_proba(self,x):\n",
        "    #x= x.reshape(-x.shape[0],1)\n",
        "    d= x.shape[1]\n",
        "    k= self.mu.shape[0]\n",
        "    k_class=k # Number of classes we have in our case it's k = 2\n",
        "    \n",
        "    ## START THE LEARNING: estimate mu, phi and sigma\n",
        "    score= np.zeros((x.shape[0], self.mu.shape[0]))\n",
        "    for label in range(k_class):\n",
        "      \n",
        "      sigma_det = np.linalg.det(self.sigma[label])**(1/2)\n",
        "      sigma_inv = np.linalg.inv(self.sigma[label])\n",
        "      \n",
        "      for i in range(x.shape[0]):\n",
        "        \n",
        "        d1 = (2*pi)**(d/2)\n",
        "        \n",
        "        part1=1/2*((x[i] - self.mu[label]).T@sigma_inv@(x[i] - self.mu[label]))\n",
        "        score[i,label] = 1/(d1 * sigma_det)*np.exp(-part1)*self.phi[label]\n",
        "\n",
        "        \n",
        "    return score\n",
        "\n",
        "\n",
        "  def predict(self,x):\n",
        "    predict = self.predict_proba(x)\n",
        "    y_preds = np.argmax(predict,axis=1)\n",
        "    return y_preds\n",
        "  \n",
        "  def accuracy(self, y, ypreds):\n",
        "    accuracy = np.mean(y==ypreds)*100\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "1ocKLDAfceF0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= GDA()\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "l_qO0Yp1c3Is"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yproba= model.predict_proba(X_test)\n",
        "yproba"
      ],
      "metadata": {
        "id": "NKY1eojY1l4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c832186-86af-430c-a31d-80cf35d144bd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.87551113e-071, 2.82297074e-002],\n",
              "       [2.37487273e-021, 9.62396112e-003],\n",
              "       [6.44627142e-002, 1.22568101e-004],\n",
              "       [7.69090333e-093, 2.23292998e-002],\n",
              "       [9.94171011e-106, 1.61072059e-002],\n",
              "       [1.10167268e-053, 5.59603853e-002],\n",
              "       [8.96175586e-002, 7.44596253e-003],\n",
              "       [4.40597225e-013, 4.87697985e-002],\n",
              "       [1.34083125e-001, 5.10291966e-006],\n",
              "       [7.07066977e-005, 1.53733708e-002],\n",
              "       [6.91282393e-065, 5.94779155e-003],\n",
              "       [2.68979935e-016, 2.57221552e-002],\n",
              "       [9.60462265e-037, 5.60969210e-003],\n",
              "       [5.44006703e-017, 1.02452087e-002],\n",
              "       [1.28436092e-002, 9.37827696e-009],\n",
              "       [1.22696279e-070, 1.65288199e-002],\n",
              "       [2.05269185e-051, 2.86882188e-004],\n",
              "       [2.17903307e-057, 5.42213232e-002],\n",
              "       [1.47629469e-008, 1.36118159e-002],\n",
              "       [1.82861034e-061, 4.77607222e-002],\n",
              "       [7.75586997e-089, 8.49746019e-003],\n",
              "       [1.05511050e-001, 1.30588878e-003],\n",
              "       [5.60612982e-060, 3.62750906e-002],\n",
              "       [5.69452501e-028, 1.14033538e-002],\n",
              "       [6.95018408e-002, 1.65371399e-004],\n",
              "       [4.36008469e-058, 7.67910148e-003],\n",
              "       [3.46254901e-027, 5.41206266e-002],\n",
              "       [6.03995583e-002, 1.13369902e-006],\n",
              "       [2.15383202e-014, 2.50040843e-002],\n",
              "       [5.84249366e-002, 3.92518120e-003],\n",
              "       [4.14598055e-002, 5.72312632e-004],\n",
              "       [4.73525796e-188, 1.61317345e-003],\n",
              "       [1.14721815e-022, 5.59675493e-002],\n",
              "       [4.02977077e-039, 3.05887489e-002],\n",
              "       [2.24593385e-004, 5.16205519e-003],\n",
              "       [1.98698665e-003, 1.65705739e-005],\n",
              "       [1.85118014e-009, 1.80581008e-004],\n",
              "       [4.48406240e-030, 4.19972027e-002],\n",
              "       [2.76773197e-013, 4.13015817e-002],\n",
              "       [4.87212743e-060, 1.92582135e-002],\n",
              "       [1.09059902e-078, 2.88724864e-002],\n",
              "       [2.99674000e-002, 1.20545342e-003],\n",
              "       [3.58409293e-003, 2.24751911e-004],\n",
              "       [2.97867645e-093, 1.15290124e-002],\n",
              "       [5.81352946e-003, 2.69147950e-007],\n",
              "       [4.36642306e-003, 3.03251326e-010],\n",
              "       [3.08847259e-002, 5.76134930e-006],\n",
              "       [4.07820305e-002, 3.65814674e-005],\n",
              "       [8.34968451e-019, 9.25995329e-004],\n",
              "       [1.35727771e-001, 3.27768626e-003],\n",
              "       [2.00238400e-002, 4.31171459e-003],\n",
              "       [1.50114890e-001, 8.50215286e-006],\n",
              "       [7.85487081e-087, 3.19782369e-002],\n",
              "       [2.36834399e-002, 6.51760151e-005],\n",
              "       [1.59065047e-009, 1.54452995e-002],\n",
              "       [1.57737761e-001, 8.57718193e-005],\n",
              "       [3.12772129e-002, 6.52047163e-004],\n",
              "       [9.28057275e-006, 3.32308245e-002],\n",
              "       [4.05493421e-002, 7.50879419e-004],\n",
              "       [1.24068014e-001, 2.45572922e-004],\n",
              "       [2.25216288e-020, 1.02193508e-002],\n",
              "       [8.33957672e-002, 1.08026477e-002],\n",
              "       [8.90559827e-003, 3.26985736e-007],\n",
              "       [2.21839246e-002, 1.54516121e-010],\n",
              "       [7.89828578e-035, 1.13723275e-002],\n",
              "       [2.52659257e-002, 8.90710026e-010],\n",
              "       [4.89641731e-028, 4.12948959e-002],\n",
              "       [4.92061239e-027, 4.39143315e-002],\n",
              "       [6.65225790e-002, 3.74362570e-004],\n",
              "       [5.27522211e-003, 9.16007758e-015],\n",
              "       [7.75569894e-002, 1.44750148e-005],\n",
              "       [1.23444641e-001, 2.25843575e-004],\n",
              "       [7.08049983e-002, 3.28708299e-003],\n",
              "       [2.30293914e-012, 4.31883087e-002],\n",
              "       [2.55182089e-052, 4.50597575e-002],\n",
              "       [2.93459547e-078, 2.49845588e-002],\n",
              "       [2.71505272e-002, 8.08520676e-004],\n",
              "       [5.89944662e-002, 6.35243606e-004],\n",
              "       [3.78790386e-070, 3.15831312e-002],\n",
              "       [1.16986192e-001, 3.40116499e-003],\n",
              "       [5.81165018e-022, 1.20228159e-002],\n",
              "       [1.66195213e-018, 2.73574021e-003],\n",
              "       [1.40945791e-002, 1.19991352e-002],\n",
              "       [1.24716119e-002, 1.47633856e-012],\n",
              "       [2.76765697e-015, 5.25792736e-002],\n",
              "       [1.22716982e-073, 2.86726052e-002],\n",
              "       [5.33329163e-062, 4.31779697e-002],\n",
              "       [2.15347573e-026, 1.97729485e-002],\n",
              "       [2.32275916e-002, 1.82508426e-002],\n",
              "       [4.47118220e-011, 9.66665355e-004],\n",
              "       [4.37763116e-166, 1.43017102e-003],\n",
              "       [2.03501243e-004, 7.11123609e-003],\n",
              "       [2.80286798e-054, 5.11075158e-002],\n",
              "       [1.10557522e-003, 2.47659770e-016],\n",
              "       [1.27991942e-003, 6.71077509e-019],\n",
              "       [8.33160805e-002, 1.07479882e-003],\n",
              "       [1.31751096e-001, 3.46825893e-003],\n",
              "       [1.37127877e-002, 1.11569180e-012],\n",
              "       [1.23552138e-044, 4.04062949e-002],\n",
              "       [1.91645173e-002, 1.21536037e-006],\n",
              "       [4.98528652e-029, 4.78359299e-002],\n",
              "       [1.17660512e-002, 2.83449136e-006],\n",
              "       [1.95644535e-050, 2.05609901e-002],\n",
              "       [1.59154121e-002, 1.09558947e-006],\n",
              "       [7.45812038e-042, 3.26154740e-002],\n",
              "       [3.93418302e-002, 8.08501976e-005],\n",
              "       [3.98590911e-004, 1.10669715e-002],\n",
              "       [1.13834550e-002, 1.42879975e-006],\n",
              "       [1.02445303e-001, 4.50714238e-005],\n",
              "       [1.57768171e-095, 8.99029222e-003],\n",
              "       [5.01401958e-100, 1.50578203e-002],\n",
              "       [4.74302665e-009, 6.39898369e-004],\n",
              "       [2.32998681e-058, 1.77381862e-002],\n",
              "       [1.87147972e-036, 3.93564281e-002],\n",
              "       [6.52886373e-012, 4.48538065e-002],\n",
              "       [1.60612033e-001, 2.20900692e-003],\n",
              "       [4.18122196e-050, 3.11259787e-002],\n",
              "       [6.58388862e-002, 4.88179945e-004],\n",
              "       [1.05306429e-001, 3.13559620e-008],\n",
              "       [1.60151755e-006, 3.82252071e-002],\n",
              "       [1.22053662e-001, 3.65077044e-003],\n",
              "       [2.00376905e-002, 1.53428438e-005],\n",
              "       [8.66272653e-003, 7.86242206e-008],\n",
              "       [1.65077396e-158, 7.71755496e-003],\n",
              "       [9.30650414e-007, 1.90754900e-002],\n",
              "       [3.09652753e-006, 7.43138914e-003],\n",
              "       [8.11651985e-002, 5.80540923e-003],\n",
              "       [1.30380698e-191, 4.28268925e-004],\n",
              "       [8.55397646e-003, 9.06884577e-017],\n",
              "       [2.96765892e-032, 5.80688546e-002],\n",
              "       [4.08012359e-009, 3.95790997e-002],\n",
              "       [1.65643171e-003, 1.68901904e-002],\n",
              "       [3.38693168e-002, 6.27587527e-004],\n",
              "       [3.86144124e-002, 8.97013531e-015],\n",
              "       [3.87284481e-002, 7.50051380e-009],\n",
              "       [5.87831907e-040, 4.07901349e-002],\n",
              "       [2.42472946e-057, 2.94487235e-003],\n",
              "       [8.61399244e-002, 1.00364940e-007],\n",
              "       [1.24722140e-003, 6.90671367e-003],\n",
              "       [1.49658469e-010, 3.44995800e-003],\n",
              "       [8.04843185e-006, 3.35435881e-003],\n",
              "       [2.75621052e-011, 3.50447545e-002],\n",
              "       [3.76042981e-002, 4.17345288e-003],\n",
              "       [2.73279309e-034, 3.11794421e-003],\n",
              "       [1.07967518e-132, 1.45950373e-002],\n",
              "       [9.12084919e-003, 2.27750017e-002],\n",
              "       [1.11750920e-035, 1.31594580e-002],\n",
              "       [1.85176007e-003, 2.36337549e-002],\n",
              "       [4.64796498e-025, 1.21953086e-002],\n",
              "       [1.87971648e-004, 1.99811570e-002],\n",
              "       [5.14961659e-002, 2.83784198e-004],\n",
              "       [3.76549991e-003, 2.12491101e-002],\n",
              "       [5.04935303e-074, 2.67922825e-002],\n",
              "       [2.20633597e-018, 2.66256560e-002],\n",
              "       [1.55448485e-001, 1.44377153e-003],\n",
              "       [2.86092787e-145, 2.63163616e-003],\n",
              "       [2.42415225e-008, 1.50376941e-002],\n",
              "       [4.87106879e-020, 3.03201262e-002],\n",
              "       [8.38698584e-002, 2.80480154e-004],\n",
              "       [1.54407475e-001, 6.73241381e-005],\n",
              "       [1.22080522e-001, 6.46136647e-004],\n",
              "       [6.24173794e-003, 3.10018833e-021],\n",
              "       [5.28142504e-028, 1.62221781e-002],\n",
              "       [7.55988537e-002, 4.09077203e-005],\n",
              "       [2.60815017e-002, 2.65811787e-006],\n",
              "       [7.58079777e-002, 7.78825710e-010],\n",
              "       [3.14786978e-002, 4.80674588e-006],\n",
              "       [1.33891979e-001, 5.53397317e-003],\n",
              "       [6.10241205e-002, 2.94464070e-008],\n",
              "       [2.31688294e-030, 1.38759721e-002],\n",
              "       [5.07363537e-002, 1.33546520e-003],\n",
              "       [6.86428671e-063, 2.53681033e-002],\n",
              "       [1.85243641e-002, 4.97218395e-005],\n",
              "       [3.00774106e-003, 4.51860120e-011],\n",
              "       [5.08675037e-003, 1.03205849e-013],\n",
              "       [1.53186974e-034, 2.34445621e-002],\n",
              "       [9.88856488e-063, 1.44363890e-002],\n",
              "       [5.30105303e-003, 9.87537014e-004],\n",
              "       [8.05316374e-013, 3.49022618e-003],\n",
              "       [5.51248972e-033, 2.51663428e-002],\n",
              "       [3.53784844e-025, 9.58010717e-003],\n",
              "       [5.54322733e-004, 3.96573597e-022],\n",
              "       [4.32066927e-003, 3.77569278e-007],\n",
              "       [1.24758189e-034, 5.53131166e-002],\n",
              "       [2.88850391e-004, 2.39352663e-003],\n",
              "       [4.05386302e-025, 2.84486484e-002],\n",
              "       [9.59656968e-168, 4.98988911e-003],\n",
              "       [1.36758107e-069, 4.08053675e-002],\n",
              "       [9.55320942e-002, 2.30778080e-006],\n",
              "       [1.73748510e-002, 1.13501469e-005],\n",
              "       [2.55638909e-002, 1.84442494e-004],\n",
              "       [8.49872670e-077, 3.86980008e-002],\n",
              "       [4.47157227e-002, 1.61635165e-004],\n",
              "       [9.05492629e-040, 1.70132084e-002],\n",
              "       [9.28754197e-100, 4.17930288e-003],\n",
              "       [8.25829092e-002, 3.77753623e-004],\n",
              "       [2.81721783e-103, 1.54145712e-002],\n",
              "       [1.49000697e-024, 8.85254862e-003],\n",
              "       [4.20571927e-095, 1.26684675e-002],\n",
              "       [1.78585061e-003, 5.32311519e-025]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6SBMPbYob9Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypreds= model.predict(X_test)\n",
        "ypreds\n"
      ],
      "metadata": {
        "id": "D4clV6PK1UJK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4d8083-9b4b-4ca8-d936-ab71cf411cde"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
              "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1,\n",
              "       1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.accuracy(y_test, ypreds)"
      ],
      "metadata": {
        "id": "QgG1xPUg1ULw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1511ed4-845d-4b65-b641-a2a783291fb1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98.0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "LUm-z8SPmj6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogisticRegression:\n",
        "  '''\n",
        "  The goal of this class is to create a LogisticRegression class, \n",
        "  that we will use as our model to classify data point into a corresponding class\n",
        "  '''\n",
        "  def __init__(self,lr,n_epochs):\n",
        "    self.lr = lr\n",
        "    self.n_epochs = n_epochs\n",
        "    self.train_losses = []\n",
        "    self.w = None\n",
        "    self.weight = []\n",
        "\n",
        "  def add_ones(self, x):\n",
        "    one = np.ones((x.shape[0],1))\n",
        "    return np.hstack((one,x))\n",
        "\n",
        "  def sigmoid(self, x):\n",
        "    return 1/(1+np.exp(-x@self.w))\n",
        "\n",
        "\n",
        "  def cross_entropy(self, x, y_true):\n",
        "    y_pred = self.sigmoid(x)\n",
        "    loss = -np.mean(y_true*np.log(y_pred)+(1-y_true)*np.log(1-y_pred))\n",
        "    return loss\n",
        "  \n",
        "  def predict_proba(self,x):  #This function will use the sigmoid function to compute the probalities\n",
        "    x= self.add_ones(x)\n",
        "    proba = self.sigmoid(x)\n",
        "    return proba\n",
        "\n",
        "\n",
        "  def predict(self,x):\n",
        "    probas = self.predict_proba(x)\n",
        "    output = [0 if p<0.5 else 1 for p in probas]#np.where(probas>=0.5, 1, 0)      #convert the probalities into 0 and 1 by using a treshold=0.5\n",
        "    return output\n",
        " \n",
        "\n",
        "  def fit(self,x,y):\n",
        "    # Add ones to x\n",
        "    x=self.add_ones(x)\n",
        "\n",
        "    # reshape y if needed\n",
        "    y=y.reshape(-1,1)\n",
        "\n",
        "    # Initialize w to zeros vector >>> (x.shape[1])\n",
        "    self.w=np.zeros((x.shape[1],1))\n",
        "\n",
        "    for epoch in range(self.n_epochs):\n",
        "      # make predictions\n",
        "      ypred = self.sigmoid(x)\n",
        "\n",
        "      #compute the gradient\n",
        "      dl = (-1/x.shape[0])*(x.T@(y-ypred))\n",
        "\n",
        "      #update rule\n",
        "      self.w=self.w-self.lr*dl\n",
        "\n",
        "      #Compute and append the training loss in a list\n",
        "      loss = self.cross_entropy(x,y)\n",
        "      self.train_losses.append(loss)\n",
        "\n",
        "      if epoch%1000 == 0:\n",
        "        print(f'loss for epoch {epoch}  : {loss}')\n",
        "\n",
        "  def accuracy(self,y_true, y_pred):\n",
        "    ##### WRITE YOUR CODE HERE #####\n",
        "    acc = np.mean(y_true==y_pred)*100\n",
        "    return acc\n",
        "    #### END CODE ####"
      ],
      "metadata": {
        "id": "rNAULU9lpZdL"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(0.1,n_epochs=10000)\n",
        "model.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "8cvRcUO2rtKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba34ba6e-1746-46f1-9582-0f0945221ec2"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss for epoch 0  : 0.6463167804519787\n",
            "loss for epoch 1000  : 0.14239444677328827\n",
            "loss for epoch 2000  : 0.1382027500077721\n",
            "loss for epoch 3000  : 0.13709089867249624\n",
            "loss for epoch 4000  : 0.13671354323231316\n",
            "loss for epoch 5000  : 0.13656970131951102\n",
            "loss for epoch 6000  : 0.13651127569994362\n",
            "loss for epoch 7000  : 0.136486634817288\n",
            "loss for epoch 8000  : 0.1364759972819431\n",
            "loss for epoch 9000  : 0.13647133617478022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_train = model.predict(X_train)\n",
        "acc = model.accuracy(y_train,ypred_train)\n",
        "print(f\"The training accuracy is: {acc}\")\n",
        "print(\" \")\n",
        "\n",
        "ypred_test = model.predict(X_test)\n",
        "acc = model.accuracy(y_test,ypred_test)\n",
        "print(f\"The test accuracy is: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbIB6k-Lm-Qa",
        "outputId": "e0ccd0c2-582c-480c-beb9-d88143135e9c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training accuracy is: 96.0\n",
            " \n",
            "The test accuracy is: 95.0\n"
          ]
        }
      ]
    }
  ]
}