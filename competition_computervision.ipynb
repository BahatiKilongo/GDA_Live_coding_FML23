{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BahatiKilongo/GDA_Live_coding_FML23/blob/main/competition_computervision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Start Runing"
      ],
      "metadata": {
        "id": "VnSuOOSz_erJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import numpy    as np\n",
        "import datetime as dt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot   as plt\n",
        "\n",
        "from PIL               import Image\n",
        "from torch.utils.data  import Dataset\n",
        "from torch.autograd    import Variable\n",
        "from torch.optim       import lr_scheduler\n",
        "\n",
        "from torch.utils.data  import Dataset, DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision       import transforms, datasets, models\n",
        "from os                import listdir, makedirs, getcwd, remove\n",
        "from os.path           import isfile, join, abspath, exists, isdir, expanduser\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:48:41.759738Z",
          "iopub.execute_input": "2023-05-21T10:48:41.760116Z",
          "iopub.status.idle": "2023-05-21T10:48:45.396631Z",
          "shell.execute_reply.started": "2023-05-21T10:48:41.760084Z",
          "shell.execute_reply": "2023-05-21T10:48:45.395678Z"
        },
        "trusted": true,
        "id": "eHWLGeRP_erM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/kaggle/input/ammi-2023-convnets\"\n",
        "train_path = join(data_path, \"train/train\")\n",
        "test_path = join(data_path,\"test/test\")\n",
        "extraimage_path = join(data_path, \"extraimages/extraimages\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:48:45.398392Z",
          "iopub.execute_input": "2023-05-21T10:48:45.398976Z",
          "iopub.status.idle": "2023-05-21T10:48:45.404076Z",
          "shell.execute_reply.started": "2023-05-21T10:48:45.398943Z",
          "shell.execute_reply": "2023-05-21T10:48:45.402968Z"
        },
        "trusted": true,
        "id": "Hu1K9ZrI_erN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transformations for both the training and testing data\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "# Training data transformations\n",
        "train_transforms = transforms.Compose(    \n",
        "    [\n",
        "    transforms.RandomRotation(45),\n",
        "    transforms.RandomResizedCrop(512),\n",
        "    transforms.RandomHorizontalFlip(0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std),\n",
        "    transforms.RandomErasing(0.3)\n",
        "])\n",
        "\n",
        "# Testing data transformations\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(512),\n",
        "    transforms.CenterCrop(512),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=mean, std=std)\n",
        "])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:48:50.094314Z",
          "iopub.execute_input": "2023-05-21T10:48:50.094691Z",
          "iopub.status.idle": "2023-05-21T10:48:50.102254Z",
          "shell.execute_reply.started": "2023-05-21T10:48:50.094661Z",
          "shell.execute_reply": "2023-05-21T10:48:50.101352Z"
        },
        "trusted": true,
        "id": "Jz-Gn20D_erO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CassavaDataset(Dataset):\n",
        "    def __init__(self, path, transform=None):\n",
        "        self.classes = os.listdir(path)\n",
        "        self.path = [f\"{path}/{className}\" for className in self.classes]\n",
        "        self.file_list = [glob.glob(f\"{x}/*\") for x in self.path]\n",
        "        self.transform = transform\n",
        "\n",
        "        files = []\n",
        "        for i, className in enumerate(self.classes):\n",
        "            for fileName in self.file_list[i]:\n",
        "                files.append([i, className, fileName])\n",
        "        self.file_list = files\n",
        "        files = None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fileName = self.file_list[idx][2]\n",
        "        classCategory = self.file_list[idx][0]\n",
        "        im = Image.open(fileName)\n",
        "        if self.transform:\n",
        "            im = self.transform(im)\n",
        "\n",
        "        return im, classCategory\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:48:52.049980Z",
          "iopub.execute_input": "2023-05-21T10:48:52.050341Z",
          "iopub.status.idle": "2023-05-21T10:48:52.063185Z",
          "shell.execute_reply.started": "2023-05-21T10:48:52.050310Z",
          "shell.execute_reply": "2023-05-21T10:48:52.062226Z"
        },
        "trusted": true,
        "id": "kcVFrl1I_erO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = CassavaDataset(train_path, transform=train_transforms)\n",
        "test_data = CassavaDataset(test_path, transform=test_transforms)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:48:55.394338Z",
          "iopub.execute_input": "2023-05-21T10:48:55.395121Z",
          "iopub.status.idle": "2023-05-21T10:48:55.793022Z",
          "shell.execute_reply.started": "2023-05-21T10:48:55.395087Z",
          "shell.execute_reply": "2023-05-21T10:48:55.791806Z"
        },
        "trusted": true,
        "id": "AYnzlvcb_erP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_split = .2\n",
        "shuffle_dataset = True\n",
        "random_seed= 42\n",
        "\n",
        "# Creating data indices for training and validation splits:\n",
        "dataset_size = len(train_data)\n",
        "indices = list(range(dataset_size))\n",
        "split = int(np.floor(validation_split * dataset_size))\n",
        "\n",
        "if shuffle_dataset :\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "train_indices, val_indices = indices[split:], indices[:split]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:49:06.310923Z",
          "iopub.execute_input": "2023-05-21T10:49:06.311286Z",
          "iopub.status.idle": "2023-05-21T10:49:06.317796Z",
          "shell.execute_reply.started": "2023-05-21T10:49:06.311257Z",
          "shell.execute_reply": "2023-05-21T10:49:06.316833Z"
        },
        "trusted": true,
        "id": "LmFcX8n1_erP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=8,\n",
        "                                             sampler=train_sampler)\n",
        "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=8,\n",
        "                                             sampler=valid_sampler)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=8)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:49:08.784247Z",
          "iopub.execute_input": "2023-05-21T10:49:08.784916Z",
          "iopub.status.idle": "2023-05-21T10:49:08.791957Z",
          "shell.execute_reply.started": "2023-05-21T10:49:08.784861Z",
          "shell.execute_reply": "2023-05-21T10:49:08.791023Z"
        },
        "trusted": true,
        "id": "Q_TgsKti_erP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rensnet 50"
      ],
      "metadata": {
        "id": "UTkK3bUP_erQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.model = models.resnet50(pretrained=False)\n",
        "        \n",
        "        # Apply quantization to the model\n",
        "        self.model = torch.quantization.quantize_dynamic(\n",
        "            self.model, {nn.Conv2d, nn.Linear}, dtype=torch.qint8\n",
        "        )\n",
        "        \n",
        "        # Prune the model to remove unimportant connections\n",
        "        self.model = self.prune_model(self.model)\n",
        "        \n",
        "        num_ftrs = self.model.fc.in_features\n",
        "        self.model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)\n",
        "    \n",
        "    def prune_model(self, model):\n",
        "        parameters_to_prune = []\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
        "                parameters_to_prune.append((module, 'weight'))\n",
        "        prune.global_unstructured(\n",
        "            parameters_to_prune,\n",
        "            pruning_method=prune.L1Unstructured,\n",
        "            amount=0.5\n",
        "        )\n",
        "        return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:49:11.390188Z",
          "iopub.execute_input": "2023-05-21T10:49:11.390605Z",
          "iopub.status.idle": "2023-05-21T10:49:11.404344Z",
          "shell.execute_reply.started": "2023-05-21T10:49:11.390555Z",
          "shell.execute_reply": "2023-05-21T10:49:11.403338Z"
        },
        "trusted": true,
        "id": "HOoY9wbq_erQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Efficient Net"
      ],
      "metadata": {
        "id": "sZR_7zgf_erR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install efficientnet_pytorch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:49:13.179797Z",
          "iopub.execute_input": "2023-05-21T10:49:13.180156Z",
          "iopub.status.idle": "2023-05-21T10:49:27.300655Z",
          "shell.execute_reply.started": "2023-05-21T10:49:13.180126Z",
          "shell.execute_reply": "2023-05-21T10:49:27.299495Z"
        },
        "trusted": true,
        "id": "Pyy49vaj_erR",
        "outputId": "10d18fad-b79b-4184-f48a-4f79c369a986"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting efficientnet_pytorch\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet_pytorch) (2.0.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (1.11.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (4.5.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.11.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\nBuilding wheels for collected packages: efficientnet_pytorch\n  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet_pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=a97cc804b3dca1e827550f8ff9c4f428dfe96b46f2c674d9366342afc2f52324\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\nSuccessfully built efficientnet_pytorch\nInstalling collected packages: efficientnet_pytorch\nSuccessfully installed efficientnet_pytorch-0.7.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        \n",
        "        # Load the pretrained EfficientNet model\n",
        "        self.model = EfficientNet.from_pretrained('efficientnet-b0')\n",
        "        \n",
        "        # Replace the classifier head with a new one\n",
        "        num_ftrs = self.model._fc.in_features\n",
        "        self.model._fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.model(input)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:49:35.800446Z",
          "iopub.execute_input": "2023-05-21T10:49:35.801529Z",
          "iopub.status.idle": "2023-05-21T10:49:35.815195Z",
          "shell.execute_reply.started": "2023-05-21T10:49:35.801475Z",
          "shell.execute_reply": "2023-05-21T10:49:35.814352Z"
        },
        "trusted": true,
        "id": "yZwZjq2w_erS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Classifier(5)\n",
        "# criterion = torch.nn.CrossEntropyLoss()\n",
        "# #optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:49:40.165134Z",
          "iopub.execute_input": "2023-05-21T10:49:40.165880Z",
          "iopub.status.idle": "2023-05-21T10:49:40.862959Z",
          "shell.execute_reply.started": "2023-05-21T10:49:40.165826Z",
          "shell.execute_reply": "2023-05-21T10:49:40.862054Z"
        },
        "trusted": true,
        "id": "GZYRrImd_erS",
        "outputId": "1e751a62-eeaf-4bbf-896a-48340bbde4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b0-355c32eb.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet-b0-355c32eb.pth\n100%|██████████| 20.4M/20.4M [00:00<00:00, 170MB/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Loaded pretrained weights for efficientnet-b0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "# Define the number of epochs\n",
        "#num_epochs = 10\n",
        "\n",
        "# Move the model and criterion to the appropriate device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "criterion.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:49:47.590074Z",
          "iopub.execute_input": "2023-05-21T10:49:47.590439Z",
          "iopub.status.idle": "2023-05-21T10:49:50.623869Z",
          "shell.execute_reply.started": "2023-05-21T10:49:47.590409Z",
          "shell.execute_reply": "2023-05-21T10:49:50.622919Z"
        },
        "trusted": true,
        "id": "nwFEkoJK_erS",
        "outputId": "1a18dbe8-2ffc-4858-b630-28c6ac45fbfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CrossEntropyLoss()"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def train(model, criterion, data_loader, optimizer, num_epochs):\n",
        "#     \"\"\"Simple training loop for a PyTorch model.\"\"\" \n",
        "    \n",
        "#     # Make sure model is in training mode.\n",
        "#     model.train()\n",
        "    \n",
        "#     # Move model to the device (CPU or GPU).\n",
        "#     model.to(device)\n",
        "    \n",
        "#     # Exponential moving average of the loss.\n",
        "#     ema_loss = None\n",
        "\n",
        "#     print('----- Training Loop -----')\n",
        "#     # Loop over epochs.\n",
        "#     for epoch in range(num_epochs):\n",
        "        \n",
        "#       # Loop over data.\n",
        "#       for batch_idx, (features, target) in enumerate(data_loader):\n",
        "            \n",
        "#           # Forward pass.\n",
        "#         output = model(features.to(device))\n",
        "#         loss = criterion(output.to(device), target.to(device))\n",
        "\n",
        "#           # Backward pass.\n",
        "#         optimizer.zero_grad()\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#       # NOTE: It is important to call .item() on the loss before summing.\n",
        "#         if ema_loss is None:\n",
        "#             ema_loss = loss.item()\n",
        "#         else:\n",
        "#             ema_loss += (loss.item() - ema_loss) * 0.01 \n",
        "\n",
        "#       # Print out progress the end of epoch.\n",
        "#       print('Epoch: {} \\tLoss: {:.6f}'.format(epoch, ema_loss),)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:49:50.625597Z",
          "iopub.execute_input": "2023-05-21T10:49:50.626545Z",
          "iopub.status.idle": "2023-05-21T10:49:50.633968Z",
          "shell.execute_reply.started": "2023-05-21T10:49:50.626507Z",
          "shell.execute_reply": "2023-05-21T10:49:50.632015Z"
        },
        "trusted": true,
        "id": "73HXIqeq_erT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def train(model, criterion, data_loader, optimizer, num_epochs):\n",
        "    \"\"\"Simple training loop for a PyTorch model.\"\"\" \n",
        "    \n",
        "    # Make sure model is in training mode.\n",
        "    model.train()\n",
        "    \n",
        "    # Move model to the device (CPU or GPU).\n",
        "    model.to(device)\n",
        "    \n",
        "    # Exponential moving average of the loss.\n",
        "    ema_loss = None\n",
        "    \n",
        "    # List to store the losses for each epoch.\n",
        "    losses = []\n",
        "\n",
        "    print('----- Training Loop -----')\n",
        "    # Loop over epochs.\n",
        "    for epoch in range(num_epochs):\n",
        "        \n",
        "        # Loop over data.\n",
        "        for batch_idx, (features, target) in enumerate(data_loader):\n",
        "            \n",
        "            # Forward pass.\n",
        "            output = model(features.to(device))\n",
        "            loss = criterion(output.to(device), target.to(device))\n",
        "\n",
        "            # Backward pass.\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update exponential moving average of the loss.\n",
        "            if ema_loss is None:\n",
        "                ema_loss = loss.item()\n",
        "            else:\n",
        "                ema_loss += (loss.item() - ema_loss) * 0.01\n",
        "\n",
        "        # Print out progress at the end of epoch.\n",
        "        print('Epoch: {} \\tLoss: {:.6f}'.format(epoch, ema_loss))\n",
        "\n",
        "        # Append the current epoch's loss to the list.\n",
        "        losses.append(ema_loss)\n",
        "#         return losses\n",
        "    # Plot the losses.\n",
        "    plt.plot(losses)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:55:46.586431Z",
          "iopub.execute_input": "2023-05-21T10:55:46.587319Z",
          "iopub.status.idle": "2023-05-21T10:55:46.598693Z",
          "shell.execute_reply.started": "2023-05-21T10:55:46.587274Z",
          "shell.execute_reply": "2023-05-21T10:55:46.596157Z"
        },
        "trusted": true,
        "id": "LcbnROeF_erT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Traing with K-fold"
      ],
      "metadata": {
        "id": "gCh0wlO2_erT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.model_selection import KFold\n",
        "# from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "# def train(model, criterion, data_loader, optimizer, num_epochs):\n",
        "#     \"\"\"Training loop with cross-validation for a PyTorch model.\"\"\" \n",
        "\n",
        "#     # Move model to the device (CPU or GPU).\n",
        "#     model.to(device)\n",
        "    \n",
        "#     # Exponential moving average of the loss.\n",
        "#     ema_loss = None\n",
        "\n",
        "#     print('----- Training Loop -----')\n",
        "    \n",
        "#     # Define the number of folds for cross-validation.\n",
        "#     num_folds = 5\n",
        "    \n",
        "#     # Split the dataset into folds.\n",
        "#     kfold = KFold(n_splits=num_folds)\n",
        "    \n",
        "#     # Initialize lists to store losses for plotting.\n",
        "#     train_losses = []\n",
        "#     val_losses = []\n",
        "    \n",
        "#     # Loop over epochs.\n",
        "#     for epoch in range(num_epochs):\n",
        "        \n",
        "#         # Perform cross-validation within each epoch.\n",
        "#         for fold, (train_indices, val_indices) in enumerate(kfold.split(data_loader.dataset)):\n",
        "#             # Create data loaders for the training and validation sets.\n",
        "#             train_loader = torch.utils.data.DataLoader(data_loader.dataset, batch_size=data_loader.batch_size, sampler=torch.utils.data.SubsetRandomSampler(train_indices))\n",
        "#             val_loader = torch.utils.data.DataLoader(data_loader.dataset, batch_size=data_loader.batch_size, sampler=torch.utils.data.SubsetRandomSampler(val_indices))\n",
        "            \n",
        "#             print('Epoch: {}, Fold: {}'.format(epoch, fold))\n",
        "            \n",
        "#             # Create a new instance of the model for each fold.\n",
        "#             model = Classifier(num_classes=model.num_classes)\n",
        "            \n",
        "#             # Move the new model instance to the device.\n",
        "#             model.to(device)\n",
        "            \n",
        "#             # Set the model to training mode.\n",
        "#             model.train()\n",
        "            \n",
        "#             # Initialize the optimizer for each fold.\n",
        "#             optimizer = optim.Adam(model.parameters())\n",
        "            \n",
        "#             # Loop over data in the training set.\n",
        "#             for batch_idx, (features, target) in enumerate(train_loader):\n",
        "#                 # Move the features and target to the device.\n",
        "#                 features = features.to(device)\n",
        "#                 target = target.to(device)\n",
        "                \n",
        "#                 # Forward pass.\n",
        "#                 output = model(features)\n",
        "#                 loss = criterion(output, target)\n",
        "\n",
        "#                 # Backward pass.\n",
        "#                 optimizer.zero_grad()\n",
        "#                 loss.backward()\n",
        "#                 optimizer.step()\n",
        "\n",
        "#                 # Update the exponential moving average of the loss.\n",
        "#                 if ema_loss is None:\n",
        "#                     ema_loss = loss.item()\n",
        "#                 else:\n",
        "#                     ema_loss += (loss.item() - ema_loss) * 0.01 \n",
        "            \n",
        "#             # Calculate the validation loss.\n",
        "#             val_loss = 0.0\n",
        "#             num_val_batches = 0\n",
        "            \n",
        "#             # Set the model to evaluation mode.\n",
        "#             model.eval()\n",
        "            \n",
        "#             # Loop over data in the validation set.\n",
        "#             with torch.no_grad():\n",
        "#                 for val_batch_idx, (val_features, val_target) in enumerate(val_loader):\n",
        "#                     # Move the validation features and target to the device.\n",
        "#                     val_features = val_features.to(device)\n",
        "#                     val_target = val_target.to(device)\n",
        "                    \n",
        "#                     val_output = model(val_features)\n",
        "#                     val_loss += criterion(val_output, val_target).item()\n",
        "#                     num_val_batches += 1\n",
        "            \n",
        "#             # Compute the average validation loss.\n",
        "#             val_loss /= num_val_batches\n",
        "            \n",
        "#             # Set the model back to training mode.\n",
        "#             model.train()\n",
        "            \n",
        "#             # Store the losses for plotting.\n",
        "#             train_losses.append(ema_loss)\n",
        "#             val_losses.append(val_loss)\n",
        "            \n",
        "#             # Print out the training and validation losses.\n",
        "# #             print('Epoch: {} \\tFold: {} \\tTrain Loss: {:.6f}\n",
        "#             # Print out the training and validation losses.\n",
        "#             print('Epoch: {} \\tFold: {} \\tTrain Loss: {:.6f} \\tVal Loss: {:.6f}'.format(epoch, fold, ema_loss, val_loss))\n",
        "\n",
        "\n",
        "#     # Plot the loss curves.\n",
        "#     plt.plot(train_losses, label='Train Loss')\n",
        "#     plt.plot(val_losses, label='Val Loss')\n",
        "#     plt.xlabel('Epoch')\n",
        "#     plt.ylabel('Loss')\n",
        "#     plt.legend()\n",
        "#     plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:50:06.264955Z",
          "iopub.execute_input": "2023-05-21T10:50:06.265592Z",
          "iopub.status.idle": "2023-05-21T10:50:06.273726Z",
          "shell.execute_reply.started": "2023-05-21T10:50:06.265559Z",
          "shell.execute_reply": "2023-05-21T10:50:06.272675Z"
        },
        "trusted": true,
        "id": "-vVLT67F_erU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, data_loader):\n",
        "    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n",
        "    # Make sure the model is in evaluation mode.\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    print('----- Model Evaluation -----')\n",
        "    # We do not need to maintain intermediate activations while testing.\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # Loop over test data.\n",
        "        for features, target in data_loader:\n",
        "          \n",
        "            # Forward pass.\n",
        "            output = model(features.to(device))\n",
        "            \n",
        "            # Get the label corresponding to the highest predicted probability.\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            \n",
        "            # Count number of correct predictions.\n",
        "            correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
        "    # Print test accuracy.\n",
        "    percent = 100. * correct / len(valid_sampler)\n",
        "    print(f'Test accuracy: {correct} / {len(valid_sampler)} ({percent:.0f}%)')\n",
        "    torch.save(model.state_dict(), 'model.ckpt')\n",
        "    return percent"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:50:07.319389Z",
          "iopub.execute_input": "2023-05-21T10:50:07.319763Z",
          "iopub.status.idle": "2023-05-21T10:50:07.329313Z",
          "shell.execute_reply.started": "2023-05-21T10:50:07.319733Z",
          "shell.execute_reply": "2023-05-21T10:50:07.328391Z"
        },
        "trusted": true,
        "id": "QheDTuxR_erU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### test with losses"
      ],
      "metadata": {
        "id": "Opc5w6V0_erV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "\n",
        "# def test(model, data_loader):\n",
        "#     \"\"\"Measures the accuracy and losses of a model on a data set.\"\"\" \n",
        "#     # Make sure the model is in evaluation mode.\n",
        "    \n",
        "#     model.eval()\n",
        "#     correct = 0\n",
        "#     total_loss = 0.0\n",
        "#     print('----- Model Evaluation -----')\n",
        "#     # We do not need to maintain intermediate activations while testing.\n",
        "#     with torch.no_grad():\n",
        "#         # Loop over test data.\n",
        "#         for features, target in data_loader:\n",
        "#             # Forward pass.\n",
        "#             output = model(features.to(device))\n",
        "#             loss_fn=criterion(output, target)\n",
        "#             # Calculate the loss.\n",
        "#             loss = loss_fn(output, target.to(device))\n",
        "            \n",
        "#             # Accumulate the total loss.\n",
        "#             total_loss += loss.item() * features.size(0)\n",
        "            \n",
        "#             # Get the label corresponding to the highest predicted probability.\n",
        "#             pred = output.argmax(dim=1, keepdim=True)\n",
        "            \n",
        "#             # Count number of correct predictions.\n",
        "#             correct += pred.cpu().eq(target.view_as(pred)).sum().item()\n",
        "    \n",
        "#     # Calculate the average loss.\n",
        "#     avg_loss = total_loss / len(data_loader.dataset)\n",
        "    \n",
        "#     # Print test accuracy and loss.\n",
        "#     percent = 100. * correct / len(data_loader.dataset)\n",
        "#     print(f'Test accuracy: {correct} / {len(data_loader.dataset)} ({percent:.0f}%)')\n",
        "#     print(f'Average loss: {avg_loss:.4f}')\n",
        "    \n",
        "#     torch.save(model.state_dict(), 'model.ckpt')\n",
        "    \n",
        "#     return percent, avg_loss\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:50:09.744842Z",
          "iopub.execute_input": "2023-05-21T10:50:09.745215Z",
          "iopub.status.idle": "2023-05-21T10:50:09.751432Z",
          "shell.execute_reply.started": "2023-05-21T10:50:09.745186Z",
          "shell.execute_reply": "2023-05-21T10:50:09.750125Z"
        },
        "trusted": true,
        "id": "vTzOR_na_erV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# num_epochs = 10\n",
        "# losses=train(model, criterion, train_loader, optimizer, num_epochs=num_epochs)\n",
        "# percent, avg_loss=test(model, valid_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:50:11.131782Z",
          "iopub.execute_input": "2023-05-21T10:50:11.132420Z",
          "iopub.status.idle": "2023-05-21T10:50:11.137405Z",
          "shell.execute_reply.started": "2023-05-21T10:50:11.132375Z",
          "shell.execute_reply": "2023-05-21T10:50:11.136357Z"
        },
        "trusted": true,
        "id": "lI6Yg7ek_erW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 12\n",
        "train(model, criterion, train_loader, optimizer, num_epochs=num_epochs)\n",
        "test(model, valid_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T10:55:52.476218Z",
          "iopub.execute_input": "2023-05-21T10:55:52.476605Z",
          "iopub.status.idle": "2023-05-21T11:26:10.744003Z",
          "shell.execute_reply.started": "2023-05-21T10:55:52.476574Z",
          "shell.execute_reply": "2023-05-21T11:26:10.743004Z"
        },
        "trusted": true,
        "id": "OVmJBdY-_erW",
        "outputId": "68054eea-dccb-46f3-be49-a6dde7ae6bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "----- Training Loop -----\nEpoch: 0 \tLoss: 0.653557\nEpoch: 1 \tLoss: 0.595908\nEpoch: 2 \tLoss: 0.614920\nEpoch: 3 \tLoss: 0.538007\nEpoch: 4 \tLoss: 0.527225\nEpoch: 5 \tLoss: 0.480270\nEpoch: 6 \tLoss: 0.500837\nEpoch: 7 \tLoss: 0.423419\nEpoch: 8 \tLoss: 0.431046\nEpoch: 9 \tLoss: 0.447668\nEpoch: 10 \tLoss: 0.423716\nEpoch: 11 \tLoss: 0.417353\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "----- Model Evaluation -----\nTest accuracy: 1020 / 1131 (90%)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "90.18567639257294"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# print(percent)"
      ],
      "metadata": {
        "id": "Q-2EJJoI_erW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Plot the losses.\n",
        "# plt.plot(losses)\n",
        "# plt.plot(avg_loss)\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.title('Training Loss')\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-20T20:59:47.051784Z",
          "iopub.execute_input": "2023-05-20T20:59:47.052454Z",
          "iopub.status.idle": "2023-05-20T20:59:47.082181Z",
          "shell.execute_reply.started": "2023-05-20T20:59:47.052419Z",
          "shell.execute_reply": "2023-05-20T20:59:47.080959Z"
        },
        "trusted": true,
        "id": "VjfZVd5P_erX",
        "outputId": "64f9793b-971b-4684-80aa-b412ff4b653f"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Plot the losses.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mlosses\u001b[49m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
          ],
          "ename": "NameError",
          "evalue": "name 'losses' is not defined",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#     # Plot the loss curves.\n",
        "#     plt.plot(train_losses, label='Train Loss')\n",
        "#     plt.plot(val_losses, label='Val Loss')\n",
        "#     plt.xlabel('Epoch')\n",
        "#     plt.ylabel('Loss')\n",
        "#     plt.legend()\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "w-zUlAYw_erX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torchvision.models as models\n",
        "# import torchvision.transforms as transforms\n",
        "# from PIL import Image\n",
        "\n",
        "# class ResNextModel(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(ResNextModel, self).__init__()\n",
        "#         self.model = models.resnext50_32x4d(pretrained=True)\n",
        "#         self.model.eval()\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         with torch.no_grad():\n",
        "#             output = self.model(x)\n",
        "#         return output\n",
        "\n",
        "# class ViTModel(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(ViTModel, self).__init__()\n",
        "#         self.model = torch.hub.load('facebookresearch/deit:main', 'deit_base_patch16_224', pretrained=True)\n",
        "#         self.model.eval()\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         with torch.no_grad():\n",
        "#             output = self.model(x)\n",
        "#         return output\n",
        "\n",
        "# class EfficientNetModel(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(EfficientNetModel, self).__init__()\n",
        "#         self.model = torch.hub.load('rwightman/gen-efficientnet-pytorch', 'tf_efficientnet_b4_ns', pretrained=True)\n",
        "#         self.model.eval()\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         with torch.no_grad():\n",
        "#             output = self.model(x)\n",
        "#         return output\n",
        "\n",
        "# class MobileNetModel(torch.nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super(MobileNetModel, self).__init__()\n",
        "#         self.model = models.mobilenet_v3_large(pretrained=True)\n",
        "#         self.model.eval()\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         with torch.no_grad():\n",
        "#             output = self.model(x)\n",
        "#         return output\n",
        "\n",
        "# # Load and preprocess the image\n",
        "# image_path = 'path_to_your_image.jpg'\n",
        "# image = Image.open(image_path).convert('RGB')\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize(224),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "# ])\n",
        "# input_tensor = transform(image)\n",
        "# input_batch = input_tensor.unsqueeze(0)\n",
        "\n",
        "# # Create instances of the models\n",
        "# resnext_model = ResNextModel()\n",
        "# vit_model = ViTModel()\n",
        "# efficientnet_model = EfficientNetModel()\n",
        "# mobilenet_model = MobileNetModel()\n",
        "\n",
        "# # Pass the input through both models and get the outputs\n",
        "# resnext_output = resnext_model(input_batch)\n",
        "# vit_output = vit_model(input_batch)\n",
        "# efficientnet_output = efficientnet_model(input_batch)\n",
        "# mobilenet_output = mobilenet_model(input_batch)\n",
        "\n",
        "# # Calculate the mean of the outputs\n",
        "# mean_output = (resnext_output + vit_output) / 2\n",
        "\n",
        "# # Calculate the sum of the EfficientNet and MobileNet outputs\n",
        "# sum_output = efficientnet_output + mobilenet_output\n",
        "\n",
        "# # Apply argmax to obtain the final predictions\n",
        "# mean_predictions = torch.argmax(mean_output, dim=1)\n",
        "# sum_predictions = torch.argmax(sum_output, dim=1)\n",
        "\n",
        "# print(\"Mean Predictions:\", mean_predictions)\n",
        "# print(\"Sum Predictions:\", sum_predictions)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-20T19:38:39.384729Z",
          "iopub.execute_input": "2023-05-20T19:38:39.385091Z",
          "iopub.status.idle": "2023-05-20T19:38:39.733861Z",
          "shell.execute_reply.started": "2023-05-20T19:38:39.385062Z",
          "shell.execute_reply": "2023-05-20T19:38:39.732515Z"
        },
        "trusted": true,
        "id": "j6nKoiqe_erX",
        "outputId": "9657659f-ba2f-4bb9-fb46-833d2e74d596"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Load and preprocess the image\u001b[39;00m\n\u001b[1;32m     51\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_to_your_image.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 52\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     53\u001b[0m transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m     54\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;241m224\u001b[39m),\n\u001b[1;32m     55\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[1;32m     56\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m])\n\u001b[1;32m     57\u001b[0m ])\n\u001b[1;32m     58\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m transform(image)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:3236\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3233\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3235\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3236\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3237\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3239\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_your_image.jpg'"
          ],
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'path_to_your_image.jpg'",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict(model, test_loader):\n",
        "    \"\"\"Measures the accuracy of a model on a data set.\"\"\" \n",
        "    # Make sure the model is in evaluation mode.\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    predictions = []\n",
        "    #print('----- Model Evaluation -----')\n",
        "    # We do not need to maintain intermediate activations while testing.\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        # Loop over test data.\n",
        "        for features, target in test_loader:\n",
        "            model.to(device)\n",
        "          \n",
        "            # Forward pass.\n",
        "            output = model(features.to(device))\n",
        "            \n",
        "            # Get the label corresponding to the highest predicted probability.\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            predictions.extend(pred.cpu().data.numpy())\n",
        "    return predictions"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T11:28:19.990931Z",
          "iopub.execute_input": "2023-05-21T11:28:19.991409Z",
          "iopub.status.idle": "2023-05-21T11:28:20.005816Z",
          "shell.execute_reply.started": "2023-05-21T11:28:19.991361Z",
          "shell.execute_reply": "2023-05-21T11:28:20.004891Z"
        },
        "trusted": true,
        "id": "qj8hCF-4_erY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predict(model, test_loader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T11:28:21.284689Z",
          "iopub.execute_input": "2023-05-21T11:28:21.285050Z",
          "iopub.status.idle": "2023-05-21T11:29:48.723092Z",
          "shell.execute_reply.started": "2023-05-21T11:28:21.285021Z",
          "shell.execute_reply": "2023-05-21T11:29:48.722097Z"
        },
        "trusted": true,
        "id": "P8ZxlIoG_erY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "name = [test_data.file_list[i][-1].split('/')[-1] for i in range(len(test_data.file_list)) ]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T11:30:10.779921Z",
          "iopub.execute_input": "2023-05-21T11:30:10.780284Z",
          "iopub.status.idle": "2023-05-21T11:30:10.789327Z",
          "shell.execute_reply.started": "2023-05-21T11:30:10.780254Z",
          "shell.execute_reply": "2023-05-21T11:30:10.788309Z"
        },
        "trusted": true,
        "id": "-JknNjTx_erY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "sample = pd.read_csv('/kaggle/input/ammi-2023-convnets/sample_submission_file.csv')\n",
        "sample['Id'] = name"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T11:30:12.914577Z",
          "iopub.execute_input": "2023-05-21T11:30:12.915265Z",
          "iopub.status.idle": "2023-05-21T11:30:12.940041Z",
          "shell.execute_reply.started": "2023-05-21T11:30:12.915230Z",
          "shell.execute_reply": "2023-05-21T11:30:12.939158Z"
        },
        "trusted": true,
        "id": "la0WTtU8_erY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {0: 'cmd', 1: 'cbb', 2: 'cbsd', 3: 'healthy', 4: 'cgm'}\n",
        "new_preds = [mapping[int(pred)] for pred in preds]\n",
        "sample['Category'] = new_preds\n",
        "sample.to_csv('submission_whith_90.csv', index=False)\n",
        "sample.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-05-21T11:30:20.914350Z",
          "iopub.execute_input": "2023-05-21T11:30:20.914731Z",
          "iopub.status.idle": "2023-05-21T11:30:20.943473Z",
          "shell.execute_reply.started": "2023-05-21T11:30:20.914702Z",
          "shell.execute_reply": "2023-05-21T11:30:20.942586Z"
        },
        "trusted": true,
        "id": "cFpia8XY_erZ",
        "outputId": "b4bc1d66-a2ef-4079-dac9-c660d9e6e06c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "  Category                 Id\n0      cgm  test-img-1448.jpg\n1      cmd   test-img-768.jpg\n2      cmd  test-img-3481.jpg\n3      cmd  test-img-1475.jpg\n4      cgm  test-img-2498.jpg",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Category</th>\n      <th>Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cgm</td>\n      <td>test-img-1448.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>cmd</td>\n      <td>test-img-768.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>cmd</td>\n      <td>test-img-3481.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>cmd</td>\n      <td>test-img-1475.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>cgm</td>\n      <td>test-img-2498.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eDMvKu2R_erZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}